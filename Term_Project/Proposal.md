1. Research area: Reinforcement Learning
2. Important conferences: NIPS, AAMAS
3. Research topic: experience and momory efficiency in Reinforcement Learning
4. Experience and memory optimization in Reinforcement Learning - A comparison of Differentiable Neural Computer and Prioritized Experience Replay
- "Reinforcement Learning (RL) is about an agent interacting with the environment, learning an optimal policy, by trial and error, for sequential decision making problems in a wide range of fields in bothnatural and social sciences, and engineering (Sutton and Barto, 1998; 2018; Bertsekas and Tsitsiklis,1996; Bertsekas, 2012; Szepesv ́ari, 2010; Powell, 2011)." (Yuxi Li, 2018)
- One of the challenging problem of RL is that it requires "big" amount of experiences to learn from trial and error. Current algorithms in RL require agent to collect experiences, store and learn from them later (many times) using experience replay (Mnih et al, 2015). To use these experiences more efficiently, modern algorithm apply Prioritized Experience Replay to choose the experiences for learning.
- Differentiable Neural Machine (Graves et al, 2016) can learn how to store and create new data structure using Neural Network.
- Purpose of study: apply DNC to reduce the memory storage and experience needed for training an Agent in RL.

### 1. Nội dung
- Giới thiệu đề tài: Reinforcement Learning is important research area because of its potential in solving complex problem where one or more agents have to make decision with long term reward in mind (e.g., sacrifice a queen for a pawn to win a chess match ten moves later.
- Despite achieving great result recently, sample efficientcy is still a challenging topic in reinforcement learning. (provide example to recent research).
- 
